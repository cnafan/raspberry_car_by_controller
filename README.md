# 🐾 PetCar AI 项目文档

PetCar AI 是一个基于 **语音交互 + LLM + TTS** 的智能宠物小车项目。它通过服务端部署的强大 AI 模型，为小车提供实时语音识别、自然语言理解和语音合成能力，实现人车流畅的语音对话和动作控制。

---

## 🚀 核心功能

1. **语音唤醒**：小车持续监听麦克风，通过 **SenseVoice (ASR)** 识别触发词（默认为 "小车小车"）。
2. **流式对话**：唤醒后，用户发出指令，**Qwen3-1.7B (LLM)** 实时生成回复。
3. **边听边说**：LLM 的文本回复同步传入 **CosyVoice (TTS)**，生成 PCM 音频流，实时推送到小车扬声器播放。
4. **动作控制**：LLM 的回复中包含结构化的动作指令（例如 `[ACTION:forward(5)]`），由服务端解析后下发给小车端执行。

---

## 🛠️ 技术栈

### 服务端 (RTX 4060 GPU)

| 组件 | 模型/技术 | 作用 |
| :--- | :--- | :--- |
| **ASR** | SenseVoice | 流式语音识别，唤醒词检测。 |
| **LLM** | Qwen3-1.7B (Int4) | 核心对话逻辑，意图理解，动作指令生成。 |
| **TTS** | CosyVoice | 流式语音合成，生成小车回复语音。 |
| **通信** | Python `websockets` | 提供双向 WebSocket 接口，处理音频流和控制指令。 |
| **协调** | `asyncio` | 管理流式数据队列 (`streaming_manager`) 和异步任务。 |

### 小车端 (Raspberry Pi)

| 组件 | 技术/硬件 | 作用 |
| :--- | :--- | :--- |
| **输入** | PyAudio, 麦克风 | 采集 PCM 音频，并上传到服务端。 |
| **VAD** | WebRTC VAD (可选) | 本地语音活动检测，过滤静音，减少带宽占用。 |
| **输出** | PyAudio, 扬声器 | 接收服务端 PCM 流，实时播放。 |
| **通信** | Python `websockets` | WebSocket 客户端，实现音频上传/下载和指令接收。 |
| **控制** | RPi.GPIO (或同类库) | 驱动电机（前进、后退、转向）和控制状态灯。 |

---

## 📦 项目目录结构
